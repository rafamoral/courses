## Introduction to Statistical Machine Learning using R (2024)

We provide a comprehensive practical and theoretical introduction to statistical machine learning using R. We start by introducing the concepts of supervised and unsupervised learning. We firstly explore unsupervised learning, and introduce k-means and hierarchical clustering, as well as principal components analysis. We then move to supervised learning methods, and cover logistic regression and regularisation methods (such as ridge regression and the LASSO). After that, we introduce the k-nearest neighbours method, and classification and regression trees (CART). Finally, we explore extensions to CART, such as random forests and, if time allows, Bayesian additive regression trees (BART).

## Topics Covered

**Topic 1:** Introductory concepts in statistical machine learning. Unsupervised vs. supervised learning. Useful plots in classification and clustering tasks. Unsupervised learning methods: hierarchical clustering and the k-means method.

**Topic 2:** Dimension reduction techniques and principal components analysis.

**Topic 3:** Regression and classification tasks. Supervised learning methods: linear and logistic regression, regularisation methods (ridge, LASSO and elastic net).

**Topic 4:** More supervised learning methods: k-nearest neighbours, smoothing methods, splines, and generalized additive models. Cross-validation techniques.

**Topic 5:** Tree-based methods. Classification and regression trees (CART), random forests.

**Topic 6:** Extensions to tree-based methods. Bayesian additive regression trees (BART) and Boruta.

**Topic 7:** Neural networks. Fitting feedforward neural networks and multilayer perceptron using R. Selecting the number of neurons based on cross-validation and information criteria. Neural networks as statistical models.

**Topic 8:** Generalized additive models for location, scale, and shape (GAMLSS). Combining regression trees and neural networks within the GAMLSS regression framework.